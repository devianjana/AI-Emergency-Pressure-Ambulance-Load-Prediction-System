import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.cluster import DBSCAN
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error
import logging

#"""1. ENVIRONMENT SETUP"""
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

class EmergencySystemMVP:
    def __init__(self):
        # The core AI model (Foundation: Random Forest is robust for tabular data)
        self.model = RandomForestRegressor(n_estimators=100, random_state=42)
        self.is_trained = False

    # --- 2. DATA MODELING (Task: Setup primary data models) ---
    def generate_synthetic_data(self, samples=1000):
        """
        Creates a dataset including:
        - Time (Hour/Day)
        - Weather (0:Clear, 1:Rain, 2:Storm)
        - Seasonal/Festival spikes
        - Geospatial (Lat/Long)
        - Historical Arrival Logs (Target)
        """
        np.random.seed(42)
        data = {
            'hour': np.random.randint(0, 24, samples),
            'day_of_week': np.random.randint(0, 7, samples),
            'weather_score': np.random.randint(0, 3, samples), 
            'is_festival': np.random.choice([0, 1], size=samples, p=[0.9, 0.1]),
            'lat': np.random.uniform(40.70, 40.80, samples),
            'long': np.random.uniform(-74.00, -73.90, samples),
            'arrivals': np.random.randint(1, 15, samples)
        }
        # Add artificial spikes for festival hours to simulate 'Seasonal Patterns'
        df = pd.DataFrame(data)
        df.loc[df['is_festival'] == 1, 'arrivals'] += 10 
        return df

    # --- 3. GEOSPATIAL ANALYSIS (Task: Identify accident-prone hotspots) ---
    def detect_hotspots(self, df):
        """Uses DBSCAN to cluster coordinates into high-risk zones."""
        coords = df[['lat', 'long']].values
        # eps is distance (approx 100-200m), min_samples is density
        db = DBSCAN(eps=0.002, min_samples=15).fit(coords)
        df['hotspot_id'] = db.labels_
        
        num_hotspots = len(set(db.labels_)) - (1 if -1 in db.labels_ else 0)
        logger.info(f"Geospatial Task: {num_hotspots} high-risk hotspots identified.")
        return df

    # --- 4. CORE AI FEATURE (Task: Predict emergency pressure) ---
    def train_system(self, df):
        """Trains the model to predict ambulance arrival density."""
        X = df[['hour', 'day_of_week', 'weather_score', 'is_festival']]
        y = df['arrivals']
        
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        self.model.fit(X_train, y_train)
        
        # Calculate Accuracy Metric (MAE)
        preds = self.model.predict(X_test)
        error = mean_absolute_error(y_test, preds)
        
        self.is_trained = True
        logger.info(f"Model trained. Mean Absolute Error: {error:.2f} arrivals.")
        return error

    def run_test_prediction(self):
        """Simulates a real-time early alert."""
        if not self.is_trained:
            return "Error: Model not trained."
        
        # Scenario: 6 PM (18), Friday (4), Raining (1), Festival (1)
        test_scenario = np.array([[18, 4, 1, 1]])
        prediction = self.model.predict(test_scenario)
        return prediction[0]

# --- 5. EXECUTION ---
if __name__ == "__main__":
    print("--- AI EMERGENCY SYSTEM: PHASE 1 STARTING ---")
    
    # Initialize
    ai_system = EmergencySystemMVP()
    
    # Step 1: Data Acquisition
    raw_data = ai_system.generate_synthetic_data()
    
    # Step 2: Identify Hotspots
    processed_data = ai_system.detect_hotspots(raw_data)
    
    # Step 3: Train & Validate
    ai_system.train_system(processed_data)
    
    # Step 4: Test Output
    result = ai_system.run_test_prediction()
    print(f"\n[ALERT TEST] Predicted Ambulance Load for Scenario: {result:.1f} units.")
    
